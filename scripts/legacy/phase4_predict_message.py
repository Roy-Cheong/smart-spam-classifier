from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

# Load from saved model
model_path = "./model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)

# Sample messages
messages = [
    "WINNER! Claim your free prize now!",
    "Hey, can we meet at 7pm?",
    "Free crypto airdrop for all users!",
    "Iâ€™ll bring the slides for tomorrowâ€™s class."
]

# Run predictions
print("ðŸ“© Predictions:\n")
for msg in messages:
    inputs = tokenizer(msg, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        logits = model(**inputs).logits
        probs = F.softmax(logits, dim=1)
        label = torch.argmax(probs).item()
        emoji = "ðŸš« SPAM" if label == 1 else "âœ… HAM"
        print(f"{emoji} â†’ '{msg}'\n   â†’ Confidence: {probs.squeeze().tolist()}")
